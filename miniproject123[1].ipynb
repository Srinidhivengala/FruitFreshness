{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556ed97b-a438-400f-8b8d-d8c4d963998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a667541e-ff25-4701-8305-68d549106d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405cc036-0b2e-4ed0-824c-f9508e1d8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define dataset folder\n",
    "dataset_path = \"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\\\\FruQ-DB\"  # Change this to your actual dataset folder\n",
    "\n",
    "# Get all image files\n",
    "image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Assign labels based on filename\n",
    "labels = []\n",
    "for img in image_files:\n",
    "    if \"rotten\" in img.lower():  # If filename contains \"rotten\", label as 1\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)  # Otherwise, label as 0 (fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bde7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f418d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch shape: torch.Size([2, 3, 128, 128])\n",
      "Labels: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# Dummy data (Replace with your real file paths and labels)\n",
    "image_files = [\"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\\\\FruQ-DB\\\\Rotten\\\\Image91 (2).png\", \"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\\\\FruQ-DB\\\\Rotten\\\\Image93 (2).png\"]\n",
    "labels = [0, 1]\n",
    "\n",
    "# Verify list lengths\n",
    "assert len(image_files) == len(labels), \"Mismatch in image and label count\"\n",
    "\n",
    "# Custom Dataset\n",
    "class FruitDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create Dataset and Dataloader\n",
    "fruit_dataset = FruitDataset(image_files, labels, transform=transform)\n",
    "\n",
    "if len(fruit_dataset) == 0:\n",
    "    print(\"❌ Dataset is empty. Check image paths or labels.\")\n",
    "else:\n",
    "    train_loader = DataLoader(fruit_dataset, batch_size=32, shuffle=True)\n",
    "    for images, labels in train_loader:\n",
    "        print(\"✅ Batch shape:\", images.shape)\n",
    "        print(\"Labels:\", labels)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd5fcf13-9b32-4ab4-affb-443708e83ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([2, 3, 128, 128])\n",
      "Labels: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "class FruitDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "fruit_dataset = FruitDataset(image_files, labels, transform=transform)\n",
    "train_loader = DataLoader(fruit_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check dataset\n",
    "for images, labels in train_loader:\n",
    "    print(\"Batch shape:\", images.shape)\n",
    "    print(\"Labels:\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ff9a0b4-44e0-4d03-8eff-16eab81ec9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simple CNN model\n",
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FruitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 classes: fresh & rotten\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = FruitCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af056afc",
   "metadata": {},
   "source": [
    "Fruit Freshness code ,\n",
    "RGB analysis ,\n",
    "Training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5944f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Data transforms for RGB images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "data_dir = \"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\\\\FruQ-DB\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Split into train/test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c8382",
   "metadata": {},
   "source": [
    "CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da9cbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FruitCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16 * 16, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Use number of classes dynamically\n",
    "num_classes = len(class_names)\n",
    "model = FruitCNN(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c023d24",
   "metadata": {},
   "source": [
    "Training loop with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f055e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4400\n",
      "Epoch [2/10], Loss: 0.1460\n",
      "Epoch [3/10], Loss: 0.0702\n",
      "Epoch [4/10], Loss: 0.0578\n",
      "Epoch [5/10], Loss: 0.0487\n",
      "Epoch [6/10], Loss: 0.0376\n",
      "Epoch [7/10], Loss: 0.0508\n",
      "Epoch [8/10], Loss: 0.0450\n",
      "Epoch [9/10], Loss: 0.0263\n",
      "Epoch [10/10], Loss: 0.0223\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1bdcdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fresh', 'Mild', 'Rotten']\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "print(class_names)\n",
    "print(\"Number of classes:\", len(class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5c4cd",
   "metadata": {},
   "source": [
    "Sample image prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4805bfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predicted: Rotten (99.22% confidence)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dim\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "\n",
    "    return class_names[predicted_class], confidence\n",
    "\n",
    "# Example usage\n",
    "img_path = \"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\\\\FruQ-DB\\\\Rotten\\\\Image93 (2).png\"\n",
    "label, confidence = predict_image(img_path, model, transform, class_names)\n",
    "print(f\"✅ Predicted: {label} ({confidence*100:.2f}% confidence)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a95e9",
   "metadata": {},
   "source": [
    "Sample Rotten Image Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87beaa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predicted: Rotten (100.00% confidence)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dim\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "\n",
    "    return class_names[predicted_class], confidence\n",
    "\n",
    "# Example usage\n",
    "img_path = \"C:\\\\Users\\\\srini\\\\Downloads\\\\image11.png\"\n",
    "label, confidence = predict_image(img_path, model, transform, class_names)\n",
    "print(f\"✅ Predicted: {label} ({confidence*100:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf7e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fruit_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76697e1c",
   "metadata": {},
   "source": [
    "Model Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd9c7f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FruitCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=32768, out_features=256, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.3, inplace=False)\n",
       "    (13): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"fruit_model.pth\", map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcaaf3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c17a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srini\\AppData\\Local\\Microsoft\\Windows\\INetCache\\IE\\W401EFVR\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create 'models' directory if it doesn't exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Now save the model\n",
    "torch.save(model.state_dict(), \"models/fruit_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srini\\AppData\\Local\\Microsoft\\Windows\\INetCache\\IE\\W401EFVR\\models\\fruit_model.pth\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(\"models/fruit_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "print(zipfile.is_zipfile(\"models/fruit_model.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fae70ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (5.23.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (2.2.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: packaging in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (2.11.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.11.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (4.13.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\srini\\desktop\\food-freshness-backend\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f62d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict_by_filename(image):\n",
    "    # Get filename (Gradio gives PIL Image with .filename attribute)\n",
    "    filename = getattr(image, \"filename\", \"\")\n",
    "    if not filename:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    name = filename.lower()\n",
    "    if \"fresh\" in name:\n",
    "        return \"fresh\"\n",
    "    elif \"rotten\" in name:\n",
    "        return \"rotten\"\n",
    "    else:\n",
    "        return \"Unknown (filename does not indicate freshness)\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_by_filename,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"label\",\n",
    "    title=\"Fruit Freshness Predictor \",\n",
    "    description=\"Predicts freshness based on image filename.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14738d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59705f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FruitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)  # Adjust if input size changes\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260990d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\srini\\AppData\\Local\\Temp\\ipykernel_25320\\2727588094.py\", line 6, in predict\n",
      "    image = transform(image).unsqueeze(0).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'transform' is not defined. Did you mean: 'transforms'?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "label_map_rev = {0: \"fresh\", 1: \"rotten\"}\n",
    "\n",
    "def predict(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probs, 1)\n",
    "        return {label_map_rev[0]: float(probs[0][0]), label_map_rev[1]: float(probs[0][1])}\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"Fruit Freshness Detector\",\n",
    "    description=\"Upload an image of a fruit to predict if it's fresh or rotten.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c682dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\srini\\AppData\\Local\\Temp\\ipykernel_25320\\2502790475.py\", line 14, in predict_from_path\n",
      "    name = image_path.lower()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\srini\\Desktop\\food-freshness-backend\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\srini\\AppData\\Local\\Temp\\ipykernel_25320\\2502790475.py\", line 14, in predict_from_path\n",
      "    name = image_path.lower()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to dataset folder\n",
    "dataset_path = \"C:\\\\Users\\\\srini\\\\Downloads\\\\FruQ-DB\"\n",
    "\n",
    "# List image files from dataset\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "image_paths = [os.path.join(dataset_path, f) for f in image_files]\n",
    "\n",
    "def predict_from_path(image_path):\n",
    "    # Rule-based dummy logic (filename-based prediction)\n",
    "    name = image_path.lower()\n",
    "    if \"fresh\" in name:\n",
    "        label = \"fresh\"\n",
    "    elif \"rotten\" in name:\n",
    "        label = \"rotten\"\n",
    "    else:\n",
    "        label = \"unknown\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    return image, label\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_from_path,\n",
    "    inputs=gr.Dropdown(choices=image_paths, label=\"Select Fruit Image from Dataset\"),\n",
    "    outputs=[gr.Image(type=\"pil\"), gr.Label()],\n",
    "    title=\"Fruit Freshness Predictor (from Dataset)\",\n",
    "    description=\"Choose an image from the dataset to predict freshness (no model used).\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc17387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "def predict_by_filename(file):\n",
    "    if file is None:\n",
    "        return \"No file uploaded\"\n",
    "\n",
    "    filename = file.name.lower()\n",
    "\n",
    "    if \"fresh\" in filename:\n",
    "        label = \"fresh\"\n",
    "    elif \"rotten\" in filename or \"notfresh\" in filename:\n",
    "        label = \"rotten\"\n",
    "    else:\n",
    "        label = \"Unknown\"\n",
    "\n",
    "    # For visualization\n",
    "    image = Image.open(file.name)\n",
    "    return label, image\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_by_filename,\n",
    "    inputs=gr.File(label=\"Upload a fruit image file\"),\n",
    "    outputs=[\"label\", \"image\"],\n",
    "    title=\"🍌 Fruit Freshness (Filename-Based Demo)\",\n",
    "    description=\"This demo guesses freshness based on the uploaded image's filename.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f830976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\srini\\AppData\\Local\\Temp\\ipykernel_25320\\1505219969.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  dataset_path = \"C:\\\\Users\\srini\\\\Desktop\\\\fruit_dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to dataset folder\n",
    "dataset_path = \"C:\\\\Users\\srini\\\\Desktop\\\\fruit_dataset\"\n",
    "\n",
    "# List image files from dataset\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "image_paths = [os.path.join(dataset_path, f) for f in image_files]\n",
    "\n",
    "def predict_from_path(image_path):\n",
    "    # Rule-based dummy logic (filename-based prediction)\n",
    "    name = image_path.lower()\n",
    "    if \"fresh\" in name:\n",
    "        label = \"fresh\"\n",
    "    elif \"rotten\" in name:\n",
    "        label = \"rotten\"\n",
    "    else:\n",
    "        label = \"unknown\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    return image, label\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_from_path,\n",
    "    inputs=gr.Dropdown(choices=image_paths, label=\"Select Fruit Image from Dataset\"),\n",
    "    outputs=[gr.Image(type=\"pil\"), gr.Label()],\n",
    "    title=\"Fruit Freshness Predictor (from Dataset)\",\n",
    "    description=\"Choose an image from the dataset to predict freshness (no model used).\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
